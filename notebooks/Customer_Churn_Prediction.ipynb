{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7a93a0",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction using Machine Learning\n",
    "\n",
    "**Full notebook**: data loading → EDA → preprocessing → feature engineering → model training (Logistic Regression, Decision Tree, Random Forest, SVM) → evaluation & visualizations.\n",
    "\n",
    "> **Note:** Update the dataset path in the first code cell if your CSV is located elsewhere (default: `data/Telco-Customer-Churn.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c038a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_fscore_support\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (update path if needed)\n",
    "data_path = 'data/Telco-Customer-Churn.csv'  # <-- change this if your file is elsewhere\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Warning: {data_path} not found. Please place the Telco CSV at this path or update the variable.\")\n",
    "else:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print('Data loaded. Shape:', df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea41795",
   "metadata": {},
   "source": [
    "## 1) Quick Data Inspection\n",
    "\n",
    "Run the cell below to inspect types, nulls, and a basic summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "try:\n",
    "    display(df.info())\n",
    "    display(df.isnull().sum())\n",
    "    display(df.describe(include='all').T.head(30))\n",
    "except NameError:\n",
    "    print('Dataframe `df` not defined. Please run the data loading cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d5c43",
   "metadata": {},
   "source": [
    "## 2) Data Cleaning & Preprocessing\n",
    "- Convert total charges to numeric if needed\n",
    "- Drop customerID\n",
    "- Encode target variable `Churn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3931f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "if 'df' in globals():\n",
    "    data = df.copy()\n",
    "    # Drop customerID if present\n",
    "    if 'customerID' in data.columns:\n",
    "        data.drop('customerID', axis=1, inplace=True)\n",
    "    \n",
    "    # Convert TotalCharges to numeric if present (some rows may be blank)\n",
    "    if 'TotalCharges' in data.columns:\n",
    "        data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "    \n",
    "    # Show nulls introduced by conversion\n",
    "    print('Nulls per column after conversion:')\n",
    "    display(data.isnull().sum())\n",
    "    \n",
    "    # Drop rows with missing values (simple approach)\n",
    "    data.dropna(inplace=True)\n",
    "    print('Shape after dropping NA:', data.shape)\n",
    "    \n",
    "    # Map target\n",
    "    if 'Churn' in data.columns:\n",
    "        data['Churn'] = data['Churn'].map({'Yes':1, 'No':0})\n",
    "    \n",
    "    display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca72ce7",
   "metadata": {},
   "source": [
    "## 3) Exploratory Data Analysis (EDA)\n",
    "- Distribution of target\n",
    "- Numeric feature distributions\n",
    "- Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA plots\n",
    "if 'data' in globals():\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(x='Churn', data=data)\n",
    "    plt.title('Churn Distribution (0 = No, 1 = Yes)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Numeric feature distribution examples\n",
    "    num_cols = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "    num_cols = [c for c in num_cols if c != 'Churn'][:6]\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f'Distribution: {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Correlation heatmap (sampled to keep it readable)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(data[num_cols + ['Churn']].corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.title('Correlation (selected numeric features)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Run previous cells to load and clean data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc924908",
   "metadata": {},
   "source": [
    "## 4) Feature Engineering\n",
    "- One-hot encode categorical variables or label-encode them\n",
    "- Scale numeric features for algorithms like SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering & encoding\n",
    "if 'data' in globals():\n",
    "    df_fe = data.copy()\n",
    "    \n",
    "    # Separate categorical and numerical\n",
    "    cat_cols = df_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "    num_cols = df_fe.select_dtypes(include=['number']).columns.tolist()\n",
    "    num_cols = [c for c in num_cols if c != 'Churn']\n",
    "    \n",
    "    print('Categorical columns:', cat_cols)\n",
    "    print('Numeric columns:', num_cols)\n",
    "    \n",
    "    # Simple encoding: for low-cardinality categoricals use one-hot, for binary/object use LabelEncoder\n",
    "    # We'll use get_dummies for simplicity (drop_first to avoid multicollinearity)\n",
    "    df_fe = pd.get_dummies(df_fe, columns=cat_cols, drop_first=True)\n",
    "    print('Shape after get_dummies:', df_fe.shape)\n",
    "    \n",
    "    # Feature matrix and target\n",
    "    X = df_fe.drop('Churn', axis=1)\n",
    "    y = df_fe['Churn']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "    print('Train/Test shapes:', X_train.shape, X_test.shape)\n",
    "else:\n",
    "    print('Run earlier cells to prepare data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58adc1",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "We scale numeric features for SVM — using StandardScaler. For tree-based models scaling is not required but won't hurt when included in pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f333092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if 'X_train' in globals():\n",
    "    # Identify numeric columns for scaling (intersection with original num_cols)\n",
    "    numeric_features = [c for c in X_train.columns if any(ch.isdigit() or ch.isalpha() for ch in c) and c in X_train.columns]\n",
    "    # Simpler: scale all features (after get_dummies everything is numeric)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print('Data scaled.')\n",
    "else:\n",
    "    print('Prepare features first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60729e83",
   "metadata": {},
   "source": [
    "## 5) Model Training & Evaluation\n",
    "We train four models and compare accuracy, classification report, confusion matrix, and ROC AUC where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "if 'X_train' in globals():\n",
    "    # Use scaled for SVM, use unscaled for tree but it's fine to use scaled variants for consistency\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    }\n",
    "    \n",
    "    trained = {}\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        if name == 'SVM':\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_prob = model.predict_proba(X_test_scaled)[:,1]\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            # some models have predict_proba\n",
    "            try:\n",
    "                y_prob = model.predict_proba(X_test)[:,1]\n",
    "            except Exception:\n",
    "                y_prob = None\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "        \n",
    "        results[name] = {'accuracy': acc, 'report': report, 'confusion_matrix': cm, 'roc_auc': roc_auc}\n",
    "        trained[name] = model\n",
    "        \n",
    "        print(f\"{name} -> Accuracy: {acc:.4f}\", end='')\n",
    "        if roc_auc is not None:\n",
    "            print(f\", ROC AUC: {roc_auc:.4f}\")\n",
    "        else:\n",
    "            print('')\n",
    "else:\n",
    "    print('Prepare features first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9232aa",
   "metadata": {},
   "source": [
    "### Confusion Matrices & ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices and ROC curves, save outputs\n",
    "if 'results' in globals():\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    for name, res in results.items():\n",
    "        cm = res['confusion_matrix']\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'outputs/confusion_matrix_{name.replace(\" \",\"_\")}.png')\n",
    "        plt.close()\n",
    "        \n",
    "    # ROC curves\n",
    "    plt.figure(figsize=(7,6))\n",
    "    for name, model in trained.items():\n",
    "        try:\n",
    "            if name == 'SVM':\n",
    "                y_prob = model.predict_proba(X_test_scaled)[:,1]\n",
    "            else:\n",
    "                y_prob = model.predict_proba(X_test)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.3f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping ROC for {name}: {e}\")\n",
    "    plt.plot([0,1],[0,1],'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('outputs/roc_curves.png')\n",
    "else:\n",
    "    print('Run model training cell first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbc33e",
   "metadata": {},
   "source": [
    "## 6) Results Summary & Next Steps\n",
    "- Review metrics above for model selection\n",
    "- Consider hyperparameter tuning (GridSearchCV) and class imbalance handling (SMOTE, class_weight)\n",
    "\n",
    "### Save a compact summary to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results' in globals():\n",
    "    summary = []\n",
    "    for name, r in results.items():\n",
    "        summary.append({\n",
    "            'model': name,\n",
    "            'accuracy': r['accuracy'],\n",
    "            'roc_auc': r['roc_auc']\n",
    "        })\n",
    "    summary_df = pd.DataFrame(summary).sort_values('accuracy', ascending=False)\n",
    "    display(summary_df)\n",
    "    summary_df.to_csv('outputs/model_summary.csv', index=False)\n",
    "    print('Saved outputs/model_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79d19b",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Notes\n",
    "- This notebook aims to be reproducible; ensure the dataset CSV path is correct.\n",
    "- For a production-ready pipeline, separate scripts, more robust preprocessing, cross-validation, and logging are recommended.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
