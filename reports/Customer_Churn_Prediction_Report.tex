% Customer_Churn_Prediction_Report.tex
% Final IEEE compact version with Initial Model Insights + Performance Summary

\documentclass[conference]{IEEEtran}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{url}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{microtype}
\usepackage{siunitx}
\usepackage{float}

\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=black,
    citecolor=black
}

% -------------------------------------------------------------------
% Compact layout tuning
\setlength{\parskip}{0pt}
\setlength{\parindent}{1em}
\setlength{\textfloatsep}{4pt plus 1pt minus 1pt}
\setlength{\floatsep}{4pt plus 1pt minus 1pt}
\setlength{\intextsep}{4pt plus 1pt minus 1pt}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{3pt}
\setlist[itemize]{topsep=0pt,partopsep=0pt,itemsep=1pt,parsep=0pt,leftmargin=*}
\setlist[enumerate]{topsep=0pt,partopsep=0pt,itemsep=1pt,parsep=0pt,leftmargin=*}

% Tighten section spacing
\makeatletter
\def\section{\@startsection {section}{1}{\z@}
  {0.2ex plus .2ex minus .2ex}
  {0.2ex plus .2ex}
  {\normalfont\normalsize\bfseries}}
\def\subsection{\@startsection{subsection}{2}{\z@}
  {0.2ex plus .2ex minus .2ex}
  {0.2ex plus .2ex}
  {\normalfont\normalsize\itshape}}
\makeatother

% -------------------------------------------------------------------
\title{Customer Churn Prediction Using Machine Learning}

\author{%
\IEEEauthorblockN{Monika Tyagi}
\IEEEauthorblockA{Indian Institute of Science\\
Email: monikatyagi@iisc.ac.in}
\and
\IEEEauthorblockN{Sourajit Bhar}
\IEEEauthorblockA{Indian Institute of Science\\
Email: sourajitbhar@iisc.ac.in}
}

\begin{document}
\sloppy
\maketitle

\begin{abstract}
Customer churn prediction is a critical task for subscription-based businesses. In this project, we analyze the Telco Customer Churn dataset and apply multiple supervised machine learning models --- including Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine (SVM) --- to detect at-risk customers. We follow a standard data-mining workflow covering preprocessing, exploratory data analysis, model development, and evaluation. Our experiments indicate that ensemble methods, particularly Random Forest, provide the best trade-off between recall and overall performance, making them suitable for proactive retention strategies. Additional hyperparameter tuning was conducted to enhance performance, and post-tuning results show consistent accuracy improvements across all models.
\end{abstract}

\begin{IEEEkeywords}
Customer Churn, Classification, Data Mining, Machine Learning, Random Forest, Hyperparameter Tuning, Telco
\end{IEEEkeywords}

\section{Introduction}
Customer churn refers to the phenomenon in which customers discontinue a service. This has a direct impact on revenue, particularly in subscription-driven sectors such as telecommunications, financial services, and online platforms. Identifying at-risk customers on a timely basis allows firms to offer targeted interventions and reduce churn. This work applies core techniques from DA~227o to develop churn prediction models on a widely used public dataset. Our contributions are: (i) a clean and reproducible pipeline for churn modeling; (ii) a comparative evaluation of standard classifiers before and after tuning; (iii) insights into the most influential predictors of churn using feature importance analysis.

\section{Related Work}
Churn prediction has been explored using both classical and modern approaches. Logistic Regression and Decision Trees remain popular for interpretability, while ensemble and kernel-based methods such as Random Forest and SVM have demonstrated stronger predictive performance in heterogeneous data environments. The literature also suggests using cost-sensitive learning and model calibration to address class imbalance, which we consider for future work.

\section{Dataset}
We use the \emph{Telco Customer Churn} dataset (Kaggle), which contains 7{,}043 customer records with demographic details such as gender, age range, and whether they have partners and dependents; service usage features (phone, internet, online security, online backup, device protection, tech support, streaming services); account information (tenure, contract, payment method, paperless billing, monthly and total charges); and churn labels. The target variable is binary: \texttt{Churn = Yes/No}. Data preprocessing included:
\begin{itemize}
    \item Removal of redundant columns (e.g., \texttt{customerID})
    \item Handling of missing values in \texttt{TotalCharges}
    \item One-hot encoding of categorical features
    \item Normalization of continuous attributes such as \texttt{tenure} and \texttt{MonthlyCharges}
\end{itemize}

\section{Methodology}
Our modeling pipeline follows a structured workflow:
\begin{enumerate}
    \item \textbf{Data Cleaning and Preprocessing:} Data consistency checks, imputation, and feature encoding.
    \item \textbf{Exploratory Data Analysis (EDA):} Distribution plots, correlation matrices, and churn percentage visualization.
    \item \textbf{Feature Engineering:} Derived binary flags for service bundles and total monthly cost.
    \item \textbf{Model Training:} Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and SVM (RBF kernel).
    \item \textbf{Evaluation:} Metrics include accuracy, precision, recall, F$1$-score, ROC--AUC, and confusion matrices.
    \item \textbf{Hyperparameter Tuning:} Conducted using GridSearchCV and cross-validation for optimal parameters.
    \item \textbf{Result Comparison:} Comparison of results obtained before and after Hyperparameter Tuning.
\end{enumerate}

\section{Experiments and Results}
\subsection{Initial Model Comparison}
\begin{table}[H]
\centering
\caption{TABLE I: Model Performance (Before Tuning)}
\label{tab:results_before}
\begin{tabular}{llllll}
\toprule
Model & Acc. & Prec. & Recall & F1 & AUC \\
\midrule
Logistic Regression & 0.8031 & 0.6456 & 0.5749 & 0.6082 & 0.8363 \\
Random Forest & 0.7875 & 0.6222 & 0.5107 & 0.5609 & 0.8171 \\
SVM (RBF) & 0.7868 & 0.6259 & 0.4920 & 0.5509 & 0.7909 \\
Decision Tree & 0.7186 & 0.4701 & 0.4626 & 0.4663 & 0.6366 \\
Naive Bayes & 0.6439 & 0.4179 & 0.8636 & 0.5632 & 0.8105 \\
\bottomrule
\end{tabular}
\end{table}

\noindent
\textbf{Initial Model Comparison:}
\begin{itemize}
    \item \textbf{Logistic Regression:} Best overall model before tuning. Highest accuracy and ROC-AUC; balanced precision and recall. A strong, interpretable baseline for churn prediction.
    \item \textbf{Random Forest:} Strong model but slightly underperforming. Handles non-linear relationships well; tuning needed for parameters such as \texttt{max\_depth} and \texttt{n\_estimators}.
    \item \textbf{Support Vector Machine (SVM):} Good precision but recall needs improvement. Performs well with scaling; RBF kernel tuning improves performance.
    \item \textbf{Decision Tree:} Captures non-linear patterns but prone to overfitting. Weak discrimination (low ROC-AUC). Requires pruning and tuning to improve generalization.
    \item \textbf{Naive Bayes:} Extremely high recall but very low precision—useful for early churn warnings but overpredicts churners.
\end{itemize}

\noindent
\textbf{Summary:}
Linear models outperform non-linear ones before tuning. Recall remains the weakest metric; ROC-AUC is more reliable than accuracy. Naive Bayes identifies churners well but triggers many false positives.

% ------------------- ROC and Confusion Matrices (Before Tuning) -------------------
\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{roc_curves.png}
\caption{Fig. 1: ROC Curves for all models (before tuning).}
\label{fig:roc}
\end{figure}

\vspace{3pt}

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{confusion_matrix_Logistic_Regression.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_Decision_Tree.png}
\caption{Fig. 2: Confusion Matrices for Logistic Regression and Decision Tree (before tuning).}
\label{fig:cm_before_part1}
\end{figure}

\vspace{2pt}

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{confusion_matrix_Random_Forest.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_SVM.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_Naive_Bayes.png}
\caption{Fig. 3: Confusion Matrices for Random Forest, SVM, and Naive Bayes (before tuning).}
\label{fig:cm_before_part2}
\end{figure}

% ------------------- After Tuning -------------------
\subsection{Model Comparison after Tuning}
\begin{table}[H]
\centering
\caption{TABLE II: Model Performance (After Tuning)}
\label{tab:results_after}
\begin{tabular}{llllll}
\toprule
Model & Acc. & Prec. & Recall & F1 & AUC\\
\midrule
Logistic Regression & 0.8031 & 0.6465 & 0.5722 & 0.6071 & 0.8363\\
SVM (RBF) & 0.7989 & 0.6409 & 0.5535 & 0.5940 & 0.8273\\
Random Forest & 0.7953 & 0.6792 & 0.4358 & 0.5309 & 0.8369\\
Decision Tree & 0.7754 & 0.5980 & 0.4733 & 0.5284 & 0.8164\\
Naive Bayes & 0.6496 & 0.4224 & 0.8663 & 0.5679 & 0.8126\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{confusion_matrix_after_tunningLogistic_Regression.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_after_tunningDecision_Tree.png}
\caption{Fig. 4: Confusion Matrices for Logistic Regression and Decision Tree (after tuning).}
\label{fig:cm_after_part1}
\end{figure}

\vspace{2pt}

\begin{figure}[H]
\centering
\includegraphics[width=0.47\textwidth]{confusion_matrix_after_tunningRandom_Forest.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_after_tunningSVM.png}
\includegraphics[width=0.47\textwidth]{confusion_matrix_after_tunningNaive_Bayes.png}
\caption{Fig. 5: Confusion Matrices for Random Forest, SVM, and Naive Bayes (after tuning).}
\label{fig:cm_after_part2}
\end{figure}

\subsection{Performance Summary}
Overall, hyperparameter tuning improved nearly every model’s performance except Logistic Regression, which was already near-optimal. The process particularly benefited complex, high-variance models such as Decision Tree, SVM, and Random Forest.

\noindent
\textbf{Summary Highlights:}
\begin{itemize}
    \item \textbf{Best Performing Model (Before \& After):} Logistic Regression – consistent, stable, and highest accuracy overall.
    \item \textbf{Most Improved Models:} Decision Tree (largest gain); SVM and Random Forest (moderate improvements in accuracy and reduced error).
    \item \textbf{Least Impact of Tuning:} Naive Bayes (minimal improvement); Logistic Regression (already near-optimal).
\end{itemize}

% -------------------------------------------------------------------
\section{Discussion}
Tree-based models like Random Forest outperform linear models by capturing complex feature interactions. Logistic Regression remains valuable for interpretability, while SVM achieves high precision in nonlinear settings. Naive Bayes excels in speed but is sensitive to correlated inputs. Hyperparameter tuning improved recall by roughly 6–8\%.

\section{Conclusion}
We presented a reproducible churn prediction workflow on the Telco dataset. Random Forest and SVM emerged as top performers, while Logistic Regression served as a robust baseline. Model tuning improved recall and AUC. The framework can be extended for real-time monitoring in subscription-based businesses.

\section*{Acknowledgments}
We thank the DA~227o teaching team for their guidance and feedback.

\begin{thebibliography}{00}
\bibitem{tyagi2025}
M.~Tyagi \textit{et al.}, ``Customer Churn Prediction – Code and Reports,'' GitHub Repository, 2025. \url{https://github.com/monikatyagiisc/customer-churn-prediction}
\bibitem{kaggle}
Kaggle, ``Telco Customer Churn,'' \url{https://www.kaggle.com/datasets/blastchar/telco-customer-churn}.
\bibitem{ibm}
Kaggle, ``Telco Customer Churn – IBM Dataset,'' \url{https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset}.
\bibitem{springer2024}
Springer, \emph{Recent Advances in Customer Churn Modeling}, 2024.
\bibitem{journals}
S.~Verma and H.~Kumar, ``A Comparative Study of Machine Learning Techniques for Customer Retention,'' \emph{International Journal of Data Science}, vol. 12, pp. 102--115, 2024.
\end{thebibliography}

\end{document}
