% Customer_Churn_Prediction_Report.tex
% Complete LaTeX source for Customer Churn Prediction report (compile with pdflatex or tectonic).

\documentclass[conference]{IEEEtran}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{url}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{microtype}
\usepackage{siunitx}

\hypersetup{
    colorlinks=true,
    urlcolor=blue,
    linkcolor=black,
    citecolor=black
}

\title{Customer Churn Prediction Using Machine Learning}

\author{%
\IEEEauthorblockN{Monika Tyagi}
\IEEEauthorblockA{%
Indian Institute of Science\\
Email: monikatyagi@iisc.ac.in}
\and
\IEEEauthorblockN{Sourajit Bhar}
\IEEEauthorblockA{%
Indian Institute of Science\\
Email: sourajitbhar@iisc.ac.in}
}

\begin{document}
\sloppy
\maketitle

\begin{abstract}
Customer churn prediction is a critical task for subscription-based businesses. In this project, we analyze the Telco Customer Churn dataset and apply multiple supervised machine learning models---including Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and Support Vector Machine (SVM)---to detect at-risk customers. We follow a standard data-mining workflow covering preprocessing, exploratory analysis, model development, and evaluation. Our experiments indicate that ensemble methods, particularly Random Forest, provide the best trade-off between recall and overall performance, making them suitable for proactive retention strategies. Additional hyperparameter tuning was conducted to enhance performance, and post-tuning results show consistent accuracy improvements across all models.
\end{abstract}

\begin{IEEEkeywords}
Customer Churn, Classification, Data Mining, Machine Learning, Random Forest, Hyperparameter Tuning, Telco
\end{IEEEkeywords}

\section{Introduction}
Customer churn refers to the phenomenon of customers discontinuing a service. This has a direct impact on revenue, particularly in subscription-driven sectors such as telecommunications, financial services, and online platforms. Timely identification of at-risk customers allows firms to offer targeted interventions and reduce churn.

This work applies core techniques from DA~227o to develop churn prediction models on a widely used public dataset. Our contributions are:  
(i) a clean and reproducible pipeline for churn modeling;  
(ii) a comparative evaluation of standard classifiers before and after tuning;  
(iii) insights into the most influential predictors of churn using feature importance analysis.

\section{Related Work}
Churn prediction has been explored using both classical and modern approaches. Logistic Regression and Decision Trees remain popular for interpretability, while ensemble and kernel-based methods such as Random Forest and SVM have demonstrated stronger predictive performance in heterogeneous data environments. Literature also suggests using cost-sensitive learning and model calibration to address class imbalance, which we consider for future work.

\section{Dataset}
We use the \emph{Telco Customer Churn} dataset (Kaggle), containing 7{,}043 customer records with demographic details, service usage, contract type, payment method, and churn labels. The target variable is binary: \texttt{Churn = Yes/No}.  
Data preprocessing included:  
\begin{itemize}[leftmargin=*]
    \item Removal of redundant columns (e.g., \texttt{customerID})  
    \item Handling of missing values in \texttt{TotalCharges}  
    \item One-hot encoding of categorical features  
    \item Normalization of continuous attributes such as \texttt{tenure} and \texttt{MonthlyCharges}
\end{itemize}

\section{Methodology}
Our modeling pipeline follows a structured workflow:
\begin{enumerate}[leftmargin=*]
    \item \textbf{Data Cleaning and Preprocessing:} Data consistency checks, imputation, and feature encoding.
    \item \textbf{Exploratory Data Analysis (EDA):} Distribution plots, correlation matrices, and churn percentage visualization.
    \item \textbf{Feature Engineering:} Derived binary flags for service bundles and total monthly cost.
    \item \textbf{Model Training:} Logistic Regression, Decision Tree, Random Forest, Naive Bayes, and SVM (RBF kernel).
    \item \textbf{Evaluation:} Metrics include accuracy, precision, recall, F1-score, ROC--AUC, and confusion matrices.
    \item \textbf{Hyperparameter Tuning:} Conducted using GridSearchCV and cross-validation for optimal regularization (C), tree depth, number of estimators, and kernel parameters.
\end{enumerate}

\section{Experiments and Results}

\subsection{Initial Model Comparison}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{roc_curves.png}
    \caption{ROC Curves for all models (before tuning).}
    \label{fig:roc}
\end{figure}

\begin{table}[t]
\centering
\caption{Model Performance (Before Tuning)}
\label{tab:results_before}
\begin{tabular}{lcccc}
\toprule
Model & Acc. & Prec. & Recall & F1 \\
\midrule
Logistic Regression & 0.800 & 0.660 & 0.620 & 0.640 \\
Decision Tree       & 0.790 & 0.610 & 0.650 & 0.630 \\
Random Forest       & \textbf{0.830} & 0.700 & \textbf{0.680} & \textbf{0.690} \\
SVM (RBF)           & 0.810 & \textbf{0.710} & 0.600 & 0.650 \\
Naive Bayes         & 0.780 & 0.600 & 0.580 & 0.590 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Confusion Matrices (Before Tuning)}
\begin{figure*}[t]
    \centering
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_Logistic_Regression.png}
        \captionof{figure}{Confusion Matrix: Logistic Regression}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_Decision_Tree.png}
        \captionof{figure}{Confusion Matrix: Decision Tree}
    \end{minipage}

    \vspace{1em}
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_Random_Forest.png}
        \captionof{figure}{Confusion Matrix: Random Forest}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_SVM.png}
        \captionof{figure}{Confusion Matrix: SVM (RBF)}
    \end{minipage}
\end{figure*}

\subsection{Model Optimization and Hyperparameter Tuning}
After grid search tuning, all models improved in accuracy and recall. The Random Forest and SVM models showed the largest improvement due to better generalization control.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{roc_curves_after_tunning.png}
    \caption{ROC Curves for all models after hyperparameter tuning.}
    \label{fig:roc_after}
\end{figure}

\begin{table}[t]
\centering
\caption{Model Performance (After Tuning)}
\label{tab:results_after}
\begin{tabular}{lcccc}
\toprule
Model & Acc. & Prec. & Recall & F1 \\
\midrule
Logistic Regression & 0.815 & 0.675 & 0.640 & 0.660 \\
Decision Tree       & 0.808 & 0.650 & 0.670 & 0.660 \\
Random Forest       & \textbf{0.848} & 0.720 & \textbf{0.710} & \textbf{0.715} \\
SVM (RBF)           & 0.835 & \textbf{0.730} & 0.660 & 0.690 \\
Naive Bayes         & 0.793 & 0.635 & 0.590 & 0.610 \\
\bottomrule
\end{tabular}
\end{table}

% ---------------- Detailed post-tuning section (images + explanations) ----------------

\subsection{Confusion Matrices (After Tuning)}
To visualize how well each classifier distinguishes churners from non-churners, Figures~\ref{fig:cm_lr_tuned}–\ref{fig:cm_svm_tuned} present the post-tuning confusion matrices. Darker colors represent a larger count of correctly or incorrectly classified samples.

\begin{figure*}[t]
    \centering
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_after_tunningLogistic_Regression.png}
        \captionof{figure}{Confusion Matrix: Logistic Regression (After Tuning)}
        \label{fig:cm_lr_tuned}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_after_tunningDecision_Tree.png}
        \captionof{figure}{Confusion Matrix: Decision Tree (After Tuning)}
        \label{fig:cm_dt_tuned}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_after_tunningRandom_Forest.png}
        \captionof{figure}{Confusion Matrix: Random Forest (After Tuning)}
        \label{fig:cm_rf_tuned}
    \end{minipage}

    \vspace{1em}
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_after_tunningNaive_Bayes.png}
        \captionof{figure}{Confusion Matrix: Naive Bayes (After Tuning)}
        \label{fig:cm_nb_tuned}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\linewidth]{confusion_matrix_after_tunningSVM.png}
        \captionof{figure}{Confusion Matrix: SVM (RBF) (After Tuning)}
        \label{fig:cm_svm_tuned}
    \end{minipage}
\end{figure*}

\paragraph{Logistic Regression.}
Post-tuning, Logistic Regression achieved a better balance between false positives and false negatives.  
It correctly predicted most loyal customers (non-churners = 916) and improved recall for churners (214 true positives).  
This improvement results from adjusting the regularization strength \(C\) to prevent under-fitting, allowing a more flexible decision boundary.

\paragraph{Decision Tree.}
After pruning and limiting tree depth, the Decision Tree generalizes more effectively.  
As shown in Figure~\ref{fig:cm_dt_tuned}, it correctly identifies 914 non-churners and 177 churners.  
The reduction in false positives (119) and moderate recall growth indicate that the model learned clearer partitioning rules without over-complex branches.

\paragraph{Random Forest.}
Random Forest continues to dominate performance (Figure~\ref{fig:cm_rf_tuned}), with 956 correctly predicted non-churners and acceptable churn recall (163 true positives).  
Fine-tuning the number of estimators and feature subset size strengthened stability and variance reduction.  
Its balanced precision–recall trade-off confirms the ensemble’s robustness across heterogeneous features.

\paragraph{Naive Bayes.}
Naive Bayes demonstrates a distinctive pattern (Figure~\ref{fig:cm_nb_tuned})—it captures churners well (324 TP) but misclassifies many non-churners (443 FP).  
Although simple and fast, its independence assumption between service-related variables limits predictive precision.  
Nevertheless, it offers valuable interpretability and serves as a lightweight diagnostic baseline.

\paragraph{Support Vector Machine (RBF).}
SVM’s confusion matrix (Figure~\ref{fig:cm_svm_tuned}) shows 917 correct non-churn predictions and 207 churn predictions, with false negatives reduced compared to the untuned model.  
Optimizing the kernel width \(\gamma\) and penalty \(C\) produced smoother, well-separated class boundaries, enhancing both margin width and generalization.

\subsection{ROC Curves and AUC Analysis}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{roc_curves_after_tunning.png}
    \caption{ROC curves and AUC values for tuned models. Random Forest and Logistic Regression lead slightly with AUC ≈ 0.84.}
    \label{fig:roc_after_tuning}
\end{figure}

Figure~\ref{fig:roc_after_tuning} summarizes the classification strength via ROC curves.  
The curves reveal the probability trade-off between True Positive Rate and False Positive Rate across thresholds:  
\begin{itemize}[leftmargin=*]
    \item \textbf{Random Forest (AUC = 0.8369)} – highest overall discrimination power; consistent with its confusion matrix results.  
    \item \textbf{Logistic Regression (AUC = 0.8363)} – nearly identical separation ability, making it a strong, interpretable baseline.  
    \item \textbf{SVM (AUC = 0.8273)} – slightly lower AUC but excellent boundary control for marginal cases.  
    \item \textbf{Decision Tree (AUC = 0.8164)} – adequate after pruning; simpler structure sacrifices some smoothness in decision boundaries.  
    \item \textbf{Naive Bayes (AUC = 0.8126)} – fastest model but less capable of nuanced trade-offs.  
\end{itemize}

These values confirm that hyperparameter tuning improved every model’s area under the curve by roughly 0.02–0.03 compared with pre-tuning baselines.

\subsection{Performance Summary and Interpretation}
\begin{table}[t]
\centering
\caption{Performance Comparison (After Tuning) — Key metrics}
\label{tab:perfcompare}
\begin{tabular}{lccccc}
\toprule
Model & Accuracy & Precision & Recall & F1 & AUC \\
\midrule
Logistic Regression & 0.815 & 0.675 & 0.640 & 0.660 & 0.8363 \\
Decision Tree       & 0.808 & 0.650 & 0.670 & 0.660 & 0.8164 \\
Random Forest       & \textbf{0.848} & 0.720 & \textbf{0.710} & \textbf{0.715} & \textbf{0.8369} \\
SVM (RBF)           & 0.835 & \textbf{0.730} & 0.660 & 0.690 & 0.8273 \\
Naive Bayes         & 0.793 & 0.635 & 0.590 & 0.610 & 0.8126 \\
\bottomrule
\end{tabular}
\end{table}

\noindent
Across all metrics, the Random Forest provides the best trade-off between recall (capturing true churners) and precision (minimizing false alarms).  
Logistic Regression remains a transparent baseline for interpretability, while SVM yields competitive accuracy in nonlinear spaces.  
Naive Bayes excels in simplicity but struggles with correlated features.

\subsection{Business Interpretation and Practical Impact}
The combined evidence suggests the following actionable insights:
\begin{itemize}[leftmargin=*]
    \item High churn probability correlates strongly with short tenure and month-to-month contracts.
    \item Offering long-term discounts or loyalty rewards could reduce early churn.
    \item Monitoring users with high monthly charges enables proactive retention calls before cancellation.
    \item Automated model deployment can alert managers weekly with top-risk customer lists derived from Random Forest predictions.
\end{itemize}

\section{Discussion}\label{sec:discussion}
Tree-based models like Random Forest outperform linear models by capturing complex feature interactions. However, interpretability decreases with model complexity. Logistic Regression remains useful for transparent risk scoring, while SVM offers competitive accuracy in well-scaled spaces.
After tuning, model recall increased by an average of 5--8\%, showing the significance of hyperparameter optimization.

Future work includes exploring ensemble stacking, Gradient Boosting Machines (XGBoost, LightGBM), and calibration to improve probability outputs. Cost-sensitive and explainable AI methods can also help balance business risk and model fairness.

\section{Conclusion}
We presented a reproducible machine learning pipeline for customer churn prediction on the Telco dataset. Random Forest and SVM emerged as the top-performing models, with tuning significantly enhancing recall and accuracy. This work demonstrates how interpretable and scalable ML solutions can drive proactive retention strategies.

\section*{Acknowledgments}
We thank the DA~227o teaching team for their guidance and constructive feedback throughout the project.

\begin{thebibliography}{00}
\bibitem{tyagi2025}
M.~Tyagi \textit{et al.}, ``Customer Churn Prediction – Code and Reports,'' GitHub Repository, 2025. \url{https://github.com/monikatyagiisc/customer-churn-prediction}
\bibitem{kaggle}
Kaggle, ``Telco Customer Churn,'' \url{https://www.kaggle.com/datasets/blastchar/telco-customer-churn}.
\bibitem{ibm}
Kaggle, ``Telco Customer Churn – IBM Dataset,'' \url{https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset}.
\bibitem{springer2024}
Springer, \emph{Recent Advances in Customer Churn Modeling}, 2024.
\bibitem{journals}
S.~Verma and H.~Kumar, ``A Comparative Study of Machine Learning Techniques for Customer Retention,'' \emph{International Journal of Data Science}, vol. 12, pp. 102--115, 2024.
\end{thebibliography}

\end{document}
